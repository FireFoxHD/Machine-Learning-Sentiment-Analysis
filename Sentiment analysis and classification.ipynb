{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "becd9196",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a077bf",
   "metadata": {},
   "source": [
    "Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a84c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score of 4 or 5\n",
    "            return Sentiment.POSITIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f2b82",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30edb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file = './Books_small.json'\n",
    "reviews = []\n",
    "with open (file) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) # returns a python dictionary\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "        \n",
    "# To test if the import was succesfull\n",
    "# print(reviews[0].text, reviews[0].sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78077215",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd0de34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to split test data and training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divides the data 80-20 training and testing respectively\n",
    "training, testing = train_test_split(reviews,test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10d44eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the text and the sentiment part of the reviews respectively\n",
    "train_x = [x.text for x in training]\n",
    "train_y = [x.sentiment for x in training]\n",
    "\n",
    "#train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "652d33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the text and the sentiment part of the reviews respectively\n",
    "test_x = [x.text for x in testing]\n",
    "test_y = [x.sentiment for x in testing]\n",
    "\n",
    "#test_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed55d01",
   "metadata": {},
   "source": [
    "#### Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea3c697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "# fits the model and transforms the data (2 in one function)\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "#data already fitted to trainigntext data so testing test data wouldnt need to be refitted\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b0254b",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e20786",
   "metadata": {},
   "source": [
    "Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09530687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very interesting and I was born in 1937 in Nebraska.  We lived in the back of a grocery store and I remember the heat and wet sheets; cannot stand heat to this day.  It was all true, but rather drawn out and tediously redundant.  A great lesson for the later generations to preserve our resources; both land AND water.\n",
      "['POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svc = SVC(kernel = 'linear')\n",
    "clf_svc.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(test_x[3])\n",
    "print(clf_svc.predict(test_x_vectors[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5180a6a",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1df06a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very interesting and I was born in 1937 in Nebraska.  We lived in the back of a grocery store and I remember the heat and wet sheets; cannot stand heat to this day.  It was all true, but rather drawn out and tediously redundant.  A great lesson for the later generations to preserve our resources; both land AND water.\n",
      "['POSITIVE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khamali\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(test_x[3])\n",
    "print(clf_lr.predict(test_x_vectors[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859a902",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "694a6866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very interesting and I was born in 1937 in Nebraska.  We lived in the back of a grocery store and I remember the heat and wet sheets; cannot stand heat to this day.  It was all true, but rather drawn out and tediously redundant.  A great lesson for the later generations to preserve our resources; both land AND water.\n",
      "['POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(test_x[3])\n",
    "print(clf_dt.predict(test_x_vectors[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc5938",
   "metadata": {},
   "source": [
    "K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7d208be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very interesting and I was born in 1937 in Nebraska.  We lived in the back of a grocery store and I remember the heat and wet sheets; cannot stand heat to this day.  It was all true, but rather drawn out and tediously redundant.  A great lesson for the later generations to preserve our resources; both land AND water.\n",
      "['NEUTRAL']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_knn.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(test_x[3])\n",
    "print(clf_knn.predict(test_x_vectors[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299bcc23",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5d6ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC 0.815\n",
      "Accuracy of Logistic Regression 0.83\n",
      "Accuracy of Decision Tree 0.755\n",
      "Accuracy of KNN 0.785\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "print(\"Accuracy of SVC: \", clf_svc.score(test_x_vectors, test_y))\n",
    "print(\"Accuracy of Logistic Regression: \", clf_lr.score(test_x_vectors, test_y))\n",
    "print(\"Accuracy of Decision Tree: \", clf_dt.score(test_x_vectors, test_y))\n",
    "print(\"Accuracy of KNN: \", clf_knn.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffa7b466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of SVC:  [0.90434783 0.25       0.26086957]\n",
      "F1 score of Logistic Reg:  [0.90909091 0.20689655 0.31578947]\n",
      "F1 score of Decision Tree:  [0.86646884 0.19512195 0.09090909]\n",
      "F1 score of KNN:  [0.88       0.13333333 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "svc_f1 = f1_score(test_y, clf_svc.predict(test_x_vectors), average = None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE])\n",
    "print(\"F1 score of SVC: \", svc_f1)\n",
    "\n",
    "lr_f1 = f1_score(test_y, clf_lr.predict(test_x_vectors), average = None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE])\n",
    "print(\"F1 score of Logistic Reg: \", lr_f1)\n",
    "\n",
    "dt_f1 = f1_score(test_y, clf_dt.predict(test_x_vectors), average = None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE])\n",
    "print(\"F1 score of Decision Tree: \", dt_f1)\n",
    "\n",
    "knn_f1 = f1_score(test_y, clf_knn.predict(test_x_vectors), average = None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE])\n",
    "print(\"F1 score of KNN: \", knn_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40c62094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34d0ed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.count(Sentiment.POSITIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46b833e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4bf2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
